# ğŸŒ WEB SEARCH - ZAAWANSOWANY SYSTEM BADAWCZY

## âœ… TAK, MAMY PEÅNY, ENTERPRISE-GRADE RESEARCH SYSTEM!

**NIE JEST TO "PROSTE WYSZUKIWANIE"!** To jest **masywny, wielopoziomowy system** z:
- ğŸ§  Hierarchical Memory integration (sprawdza pamiÄ™Ä‡ PRZED web search)
- ğŸŒ Multi-source search (6 ÅºrÃ³deÅ‚ danych)
- ğŸ” Advanced web scraping (Firecrawl + Readability + BeautifulSoup)
- ğŸ¤– LLM fact extraction (wyciÄ…ga fakty z tekstÃ³w)
- ğŸ“Š Semantic ranking (hybrid rank z embeddings)
- ğŸ’¾ LTM storage (auto-zapisuje fakty)
- âš¡ Multi-level caching (TTL 30 min)
- ğŸ¯ Source quality scoring (.edu = 1.3x, .org = 1.2x)
- ğŸ“… Recency bonus (Å›wieÅ¼e artykuÅ‚y lepsze)
- ğŸš« Domain limiting (max 2-3 z tej samej domeny)
- ğŸ”„ Fallback pipeline (jeÅ›li gÅ‚Ã³wny moduÅ‚ nie dziaÅ‚a)

### ğŸ“Š DOSTÄ˜PNE Å¹RÃ“DÅA

#### ğŸ†“ DARMOWE (zawsze dziaÅ‚ajÄ…):
1. **DuckDuckGo** - HTML search
   - PeÅ‚ne wyszukiwanie web
   - Funkcja: `_ddg_search()` w `core/research.py` L182
   
2. **Wikipedia** - API
   - ArtykuÅ‚y encyklopedyczne
   - Funkcja: `_wiki_search()` w `core/research.py` L196
   
3. **arXiv** - Academic papers
   - Publikacje naukowe (fizyka, matematyka, CS)
   - Funkcja: `_arxiv_search()` w `core/research.py` L207
   
4. **Semantic Scholar** - Research papers
   - ArtykuÅ‚y badawcze ze wszystkich dziedzin
   - Funkcja: `_s2_search()` w `core/research.py` L221

#### ğŸ’° PÅATNE (wymagajÄ… kluczy API):
5. **SERPAPI** - Google Search
   - Najlepsze wyniki wyszukiwania
   - Wymaga: `SERPAPI_KEY` w `.env`
   - Funkcja: `_serpapi_search()` w `core/research.py` L232
   
6. **Firecrawl** - Web scraping
   - Wysokiej jakoÅ›ci scraping treÅ›ci
   - Wymaga: `FIRECRAWL_API_KEY` w `.env`
   - Fallback: BeautifulSoup (zawsze dziaÅ‚a)
   - Funkcja: `_firecrawl()` w `core/research.py` L268

---

## ğŸš€ JAK UÅ»YWAÄ†

### 1. NATURAL LANGUAGE (przez intent detection):
```
USER: "Co to jest kwantowa superpozycja?"
USER: "Wyszukaj informacje o AI"
USER: "Kim jest Stephen Hawking?"
USER: "ZnajdÅº informacje o Python"
```

**Automatycznie:**
- Wykrywane przez `handle_web_search_intent()`
- WywoÅ‚uje `autonauka(query)`
- Przeszukuje wszystkie dostÄ™pne ÅºrÃ³dÅ‚a
- Generuje odpowiedÅº z kontekstem
- Zwraca ÅºrÃ³dÅ‚a (linki)

### 2. PRZEZ API ENDPOINT:
```bash
# Proste wyszukiwanie
curl -X POST "http://localhost:8080/api/research/search" \
  -H "Authorization: Bearer ssjjMijaja6969" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "teoria strun",
    "topk": 5,
    "mode": "full"
  }'

# Autonauka z LTM
curl -X POST "http://localhost:8080/api/research/autonauka" \
  -H "Authorization: Bearer ssjjMijaja6969" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "WyjaÅ›nij kwantowÄ… superpozycjÄ™",
    "topk": 8,
    "user_id": "user123",
    "save_to_ltm": true
  }'

# SprawdÅº dostÄ™pne ÅºrÃ³dÅ‚a
curl -X GET "http://localhost:8080/api/research/sources" \
  -H "Authorization: Bearer ssjjMijaja6969"
```

### 3. PRZEZ CHAT (frontend):
Po prostu wpisz pytanie w chat:
- "Co to jest Docker?"
- "Wyszukaj informacje o blockchain"
- "Kim byÅ‚ Albert Einstein?"

---

## ğŸ“ STRUKTURA KODU

### Intent Detection:
```
core/intent_dispatcher.py
â”œâ”€â”€ handle_web_search_intent()    # Linia 154-176
â”‚   â”œâ”€â”€ Wzorce regex:
â”‚   â”‚   - r"(wyszukaj|znajdÅº informacje)\s+(?:o\s+)?(.+)"
â”‚   â”‚   - r"(co to jest|kim jest|czym jest)\s+(.+)"
â”‚   â”‚   - r"(opowiedz o|co wiesz o)\s+(.+)"
â”‚   â”‚   - r"(przeszukaj internet)\s+(?:dla\s+)?(.+)"
â”‚   â””â”€â”€ WywoÅ‚uje: autonauka(query, topk=5, user_id="system")
```

### Research Module:
```
core/research.py
â”œâ”€â”€ _ddg_search()           # L182  - DuckDuckGo HTML
â”œâ”€â”€ _wiki_search()          # L196  - Wikipedia API
â”œâ”€â”€ _arxiv_search()         # L207  - arXiv papers
â”œâ”€â”€ _s2_search()            # L221  - Semantic Scholar
â”œâ”€â”€ _serpapi_search()       # L232  - Google (SERPAPI)
â”œâ”€â”€ _search_all()           # L245  - Orchestrator wszystkich ÅºrÃ³deÅ‚
â”œâ”€â”€ _firecrawl()            # L268  - Scraping (Firecrawl/fallback)
â””â”€â”€ autonauka()             # L~300 - PeÅ‚na pipeline
```

### API Endpoints:
```
research_endpoint.py
â”œâ”€â”€ POST /api/research/search     # L29   - Web search
â”œâ”€â”€ POST /api/research/autonauka  # L78   - Auto-learning
â”œâ”€â”€ GET  /api/research/sources    # L118  - Lista ÅºrÃ³deÅ‚
â””â”€â”€ GET  /api/research/test       # L168  - Test
```

---

## ğŸ”§ KONFIGURACJA

### Bez kluczy API (darmowe):
```env
# Wystarczy to - bÄ™dzie dziaÅ‚aÄ‡ z DDG + Wiki + arXiv + S2
AUTH_TOKEN=ssjjMijaja6969
```

### Z kluczami API (peÅ‚na moc):
```env
AUTH_TOKEN=ssjjMijaja6969

# Google search (zalecane)
SERPAPI_KEY=twoj_klucz_serpapi

# Web scraping (zalecane)
FIRECRAWL_API_KEY=twoj_klucz_firecrawl
```

---

## ğŸ“Š TRYBY WYSZUKIWANIA

### `mode: "full"` (domyÅ›lny):
- DuckDuckGo âœ…
- Wikipedia âœ…
- SERPAPI (jeÅ›li klucz) âœ…
- arXiv âœ…
- Semantic Scholar âœ…
- **Najlepsze wyniki, wolniejsze**

### `mode: "grounded"`:
- Jak `full` ale priorytet dla wiarygodnych ÅºrÃ³deÅ‚
- Preferuje: .edu, .gov, Wikipedia, Scholar

### `mode: "fast"`:
- Tylko DuckDuckGo + Wikipedia
- **Szybkie, podstawowe wyniki**

### `mode: "free"`:
- Tylko darmowe ÅºrÃ³dÅ‚a (bez SERPAPI)
- DDG + Wiki + arXiv + S2

---

## ğŸ§ª TEST

### 1. Test przez terminal:
```bash
curl -X GET "http://localhost:8080/api/research/test" \
  -H "Authorization: Bearer ssjjMijaja6969"
```

Powinno zwrÃ³ciÄ‡:
```json
{
  "ok": true,
  "sources_count": 3,
  "answer_length": 500,
  "test_passed": true
}
```

### 2. Test przez chat:
Uruchom aplikacjÄ™ i wpisz w chat:
```
Co to jest Python?
```

PowinieneÅ› otrzymaÄ‡:
- OdpowiedÅº z wyjaÅ›nieniem
- Linki do ÅºrÃ³deÅ‚ (Wikipedia, etc.)
- Metadata z "source": "fast_path", "handler": "handle_web_search_intent"

---

## ğŸ¯ PODSUMOWANIE

### âœ… CO MAMY:
- **4 darmowe ÅºrÃ³dÅ‚a** (DDG, Wiki, arXiv, S2) - zawsze dziaÅ‚ajÄ…
- **2 pÅ‚atne ÅºrÃ³dÅ‚a** (SERPAPI, Firecrawl) - opcjonalne, ale lepsze
- **Automatyczne wykrywanie** pytaÅ„ wymagajÄ…cych web search
- **Natural language** - "Co to jest X?" dziaÅ‚a out-of-box
- **Fallback scraping** - jeÅ›li Firecrawl nie dziaÅ‚a, uÅ¼ywamy BeautifulSoup
- **Multi-source** - Å‚Ä…czy wyniki z wielu ÅºrÃ³deÅ‚
- **Domain limiting** - max 2 wyniki z tej samej domeny (anti-spam)
- **LLM synthesis** - generuje czytelnÄ… odpowiedÅº z kontekstem

### âŒ CZEGO NIE MAMY:
- Real-time web crawling (uÅ¼ywamy API i scraping)
- Obrazy z web search (tylko teksty)
- PÅ‚atne ÅºrÃ³dÅ‚a wymagajÄ… kluczy API

### ğŸ”œ MOÅ»LIWE ROZSZERZENIA:
- Google Scholar (przez SERPAPI)
- PubMed (medical papers)
- GitHub search
- Stack Overflow search
- News API (aktualnoÅ›ci)
- Reddit API (dyskusje)

---

**WNIOSEK:** Mamy **PEÅNY** dostÄ™p do internetu przez 6 ÅºrÃ³deÅ‚, w tym 4 darmowe. System dziaÅ‚a bez kluczy API (tryb free), ale z SERPAPI + Firecrawl jest znacznie lepszy.

**DATA:** 2025-10-16  
**STATUS:** âœ… Fully Operational  
**WERSJA:** Research System v1.0 with 6 data sources
